<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Robotic Arm with Computer Vision</title>
  <link rel="stylesheet" href="style.css">
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 0;
      padding: 0;
      line-height: 1.6;
      background-color: #121212;
      color: white;
    }

    header {
      position: relative;
      padding: 20px;
      background-color: #333;
      color: rgb(240, 170, 170);
      text-align: center;
    }

    .back-button {
      position: absolute;
      top: 20px;
      left: 20px;
      padding: 10px 15px;
      background: rgb(190, 230, 195);
      color: black;
      border: none;
      border-radius: 5px;
      cursor: pointer;
      font-size: 1rem;
    }

    #project-title {
      font-size: 3rem;
      margin: 0;
    }

    main {
      padding: 5px;
      max-width: 1200px;
      margin: 0 auto;
    }

    h1 {
      font-size: 3rem;
      margin-bottom: 20px;
    }

    h2 {
      font-size: 2rem;
      margin-bottom: 15px;
      color: white;
    }

    h3 {
      font-size: 1.5rem;
      margin-bottom: 10px;
      color: #ccc;
    }

    p {
      text-indent: 20px;
      margin-bottom: 20px;
      text-align: justify;
    }

    .image-gallery {
      display: flex;
      justify-content: center;
      gap: 20px;
      flex-wrap: wrap;
      margin-bottom: 20px;
    }

    .image-gallery img {
      max-width: 100%;
      height: auto;
      border-radius: 8px;
      box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }

    .github-button {
      position: fixed;
      top: 50px;
      right: 20px;
      background: #333;
      border: none;
      padding: 10px;
      border-radius: 50%;
      cursor: pointer;
      display: flex;
      align-items: center;
      justify-content: center;
      width: 70px;
      height: 70px;
      box-shadow: 0 4px 6px rgba(0, 0, 0, 0.2);
      z-index: 100;
    }

    .github-button img {
      width: 70px;
      height: 70px;
      margin: 0;
      border-radius: 0;
      box-shadow: none;
    }

    .menu-icon {
      position: fixed;
      top: 150px;
      right: 30px;
      background: #333;
      color: white;
      padding: 10px;
      border-radius: 5px;
      cursor: pointer;
      font-size: 1.2rem;
    }

    .popup-menu {
      display: none;
      position: fixed;
      top: 200px;
      right: 60px;
      background: #222;
      color: white;
      border: 1px solid #444;
      padding: 10px;
      border-radius: 5px;
      box-shadow: 0 4px 6px rgba(0, 0, 0, 0.2);
    }

    .popup-menu a {
      color: #00bcd4;
      text-decoration: none;
      display: block;
      margin: 5px 0;
    }

    .popup-menu a:hover {
      text-decoration: underline;
    }

    footer {
      text-align: center;
      padding: 20px;
      background: #333;
      color: white;
    }
    .code-block {
  background-color: #241f1f;
  padding: 15px;
  margin: 20px 0;
  border-radius: 5px;
  overflow-x: auto;
  color: white;
  font-family: 'Courier New', Courier, monospace;
  line-height: 1.5;
  
}
code {
  display: block;
  white-space: pre-wrap;
  word-wrap: break-word;
}
.code-block {
  background-color: #1e1e1e; /* Darker background for contrast */
  color: #d4d4d4; /* Light gray text for better readability */
  font-family: 'Courier New', Courier, monospace; /* Classic monospace font */
  padding: 20px; /* Spacious padding for a clean look */
  border-radius: 8px; /* Rounded corners for modern design */
  margin: 20px 0; /* Consistent spacing */
  border: 1px solid #333; /* Subtle border for definition */
  overflow-x: auto; /* Horizontal scrolling for long lines of code */
  box-shadow: 0 4px 6px rgba(0, 0, 0, 0.2); /* Slight shadow for depth */
}

pre {
  margin: 0; /* Remove default margins inside the code block */
  line-height: 1.5; /* Better line spacing for readability */
}

code {
  display: block; /* Ensure code wraps properly */
  white-space: pre-wrap; /* Allow code to wrap for better UX */
  word-break: break-word; /* Handle long, unbroken strings */
}

.subtitle {
  text-align: center; /* Center the text */
  color: #a0dde6; /* A distinct color (cyan in this case) */
  font-size: 1.8rem; /* Slightly smaller than main section titles */
  margin: 20px 0; /* Add spacing above and below */
  font-weight: bold; /* Make it stand out */
}
.subtitle_2 { /*for subtitle's subtitle*/
  text-align: center; /* Center the text */
  color: #a0dde6; /* A distinct color (cyan in this case) */
  font-size: 1.5rem; /* Slightly smaller than main section titles */
  margin: 20px 0; /* Add spacing above and below */
}

.image-container {
    display: flex; /* Arrange images side by side */
    justify-content: center; /* Center the images in the container */
    gap: 20px; /* Add space between the images */
    margin: 30px 0; /* Add space above and below the image container */
}

.image-container .image {
    max-width: 45%; /* Ensure images take up 45% of the container width each */
    height: auto; /* Maintain aspect ratio */
    border-radius: 8px; /* Slightly round the corners */
    box-shadow: 0 4px 6px rgba(0, 0, 0, 0.2); /* Add a shadow for depth */
}

.caption-box {
    background-color: #333; /* Dark gray background */
    color: #ddd; /* Light gray text */
    font-size: 1.2rem; /* Slightly larger font for readability */
    text-align: center; /* Center-align the caption */
    padding: 15px; /* Add padding inside the box */
    margin: 20px auto; /* Center the box and add vertical spacing */
    max-width: 80%; /* Restrict width to make it look proportional */
    border-radius: 8px; /* Add rounded corners */
    box-shadow: 0 4px 6px rgba(0, 0, 0, 0.3); /* Subtle shadow for pop-out effect */
    border: 1px solid #444; /* Add a border to separate it from the background */
}

/* I am using this to hyperlink the files*/
.highlight-link {
    text-decoration: none; /* Remove the default underline */
}

.highlight-link:hover {
    text-decoration: none; /* Ensure no underline appears on hover */
}

.highlight {
    background-color: #333; /* Dark gray background */
    color: #ddd; /* Light gray text */
    padding: 3px 6px; /* Padding around the word */
    border-radius: 4px; /* Smooth rounded edges */
    box-shadow: 0 2px 4px rgba(0, 0, 0, 0.2); /* Subtle shadow for depth */
    font-weight: bold; /* Optional: make it stand out more */
    cursor: pointer; /* Change cursor to pointer to indicate it's clickable */
}

/* Math equation container styling */
.math-block {
    background-color: #333; /* Dark grey background */
    color: #ddd; /* Light grey text */
    font-family: 'Courier New', Courier, monospace;
    font-size: 1.2rem;
    text-align: center;
    padding: 15px;
    margin: 20px auto; /* Centered with margin */
    border-radius: 8px; /* Rounded corners */
    max-width: 80%; /* Restrict width */
    box-shadow: 0 4px 6px rgba(0, 0, 0, 0.2); /* Slight shadow */
    border: 1px solid #444; /* Subtle border */
}

/* Example walkthrough styling */
.example-walkthrough {
    text-align: left; /* Align content to left */
    margin: 30px auto;
    padding: 20px;
    background-color: #1e1e1e; /* Dark background */
    color: #d4d4d4; /* Light grey text */
    border-radius: 8px;
    border: 1px solid #444;
    box-shadow: 0 4px 6px rgba(0, 0, 0, 0.3);
    max-width: 90%;
    font-size: 1.1rem;
    line-height: 1.6;
}

.example-walkthrough h2 {
    text-align: center;
    color: #a0dde6; /* Cyan-like title */
    font-size: 1.8rem;
    margin-bottom: 20px;
}

.example-walkthrough ul {
    list-style-type: disc; /* Bullet points */
    margin-left: 20px;
}

.example-walkthrough .math-inline {
    background-color: #333;
    color: #ddd;
    font-family: 'Courier New', Courier, monospace;
    padding: 3px 6px;
    border-radius: 4px;
    margin: 0 3px;
}

.code-block {
    background-color: #1e1e1e;
    color: #d4d4d4;
    font-family: 'Courier New', Courier, monospace;
    padding: 20px;
    border-radius: 8px;
    margin: 20px auto;
    max-width: 90%;
    overflow-x: auto;
    border: 1px solid #444;
    box-shadow: 0 4px 6px rgba(0, 0, 0, 0.2);
}

.code-block code {
    display: block;
    white-space: pre-wrap;
}



  </style>
</head>
<body>
  <header>
    <button onclick="goBack()" class="back-button">&larr; Back</button>
    <h1 id="project-title">Robotic Arm with Computer Vision</h1>
  </header>

  <main>
    <button class="github-button" onclick="window.open('https://github.com/nischalkharel/RoboticArm', '_blank')">
      <img src="git_logo.png" alt="GitHub">
    </button>

    <div class="menu-icon" onclick="toggleMenu()">≡</div>
    <div class="popup-menu" id="popup-menu">
      <a href="https://github.com/nischalkharel/RoboticArm/blob/main/arm.py" target="_blank">arm.py</a>
      <a href="https://github.com/nischalkharel/RoboticArm/blob/main/camera.py" target="_blank">camera.py</a>
      <a href="https://github.com/nischalkharel/RoboticArm/blob/main/calculate_angles_for.py" target="_blank">calculate_angles_for.py</a>
      <a href="https://github.com/nischalkharel/RoboticArm/blob/main/move_motor.py" target="_blank">move_motor.py</a>
      <a href="https://github.com/nischalkharel/RoboticArm/blob/main/audio_in.py" target="_blank">audio_in.py</a>
      <a href="https://github.com/nischalkharel/RoboticArm/blob/main/audio_out.py" target="_blank">audio_out.py</a>
      <a href="https://github.com/nischalkharel/RoboticArm/blob/main/KeyboardControlledArm.py" target="_blank">KeyboardControlledArm.py</a>
    </div>

    <section id="project-description">
      <h1>Design Overview</h1>
      <h2 class="subtitle">High-Level Description</h2>
      <p>For this project, I built a robotic arm that uses computer vision to detect, pick up, and place a block with a metal gripper. The block is identified using an ArUco marker, and the arm calculates its movements based on the marker’s position in 3D space. To make it more fun and interactive, I added voice control where I can say "activate now," and the arm not only starts moving but also responds with voice prompts through a speaker I added. This was probably my favorite part because it made the arm feel less like a machine and more like something you could interact with naturally.</p>

      <section id="original-design-concepts">
        <h2 class="subtitle">Original Design Concepts</h2>
        <p>When I started, my project idea was to create a robotic arm with a camera module to detect an object’s location and pick it up. At first, I planned to 3D print the arm parts and attach motors myself to build the entire structure from scratch. However, after discussing with Dr. Dickerson, I decided to use a pre-made arm shell and focus more on integrating motors, the camera module, and the software. This approach allowed me to prioritize the technical challenges of control and computer vision without being delayed by manufacturing issues.</p>
      
        <p>For the camera, I originally wanted to use a stereo camera for depth sensing since they are known for accurately measuring distances. I thought this would be crucial for ensuring precise movements of the arm. However, after experimenting, I found that the stereo camera setup was challenging to configure and calibrate. While I did manage to get it to detect and track objects using OpenCV’s checkerboard calibration technique, it wasn’t significantly more accurate than a simpler setup using a single Arducam with ArUco markers. So, I ultimately decided to use the Arducam, which was more reliable for my application. If you’re curious, I’ve uploaded my stereo camera experiments to my GitHub repository, where you can check out how I set it up.</p>
      
        <p>Initially, I also considered including precise object placement as part of the arm’s functionality. However, I realized this would make the project scope too broad for the given timeline, so I decided to focus solely on object detection and pickup. Instead of placing the object at a specific location, I kept the task simpler by having the arm place it in a pre-defined area.</p>
      
        <h3 class="subtitle_2">Changes Made from the Proposal</h3>
        <ul>
          <li><strong>Camera Placement:</strong> I hadn’t initially decided where to place the camera, but during testing, I mounted it on the base of the arm in a custom enclosure. This position gave a stable and unobstructed view of the workspace.</li>
          <li><strong>Pre-Made Arm:</strong> I shifted from the idea of 3D printing the arm to using a pre-made shell, which allowed me to focus on coding and integrating components like the servos and camera module.</li>
          <li><strong>Simplified Task:</strong> I scaled back the complexity by focusing only on picking up objects rather than precise placement.</li>
        </ul>
      </section>
      
      <h2 class="subtitle">Final Design</h2>
      <p>The final design brings together hardware and software in a system that works smoothly:</p>
      
      <ul>
        <li><strong>Arm and Gripper:</strong> The arm is made of pre-built pieces, and the metal gripper is servo-controlled to pick up and release the block.</li>
        <li><strong>Camera:</strong> An Arducam mounted on the arm base detects the block using the ArUco library. I adjusted the library’s outputs for better distance accuracy. The camera was calibrated using OpenCV’s checkerboard calibration method.</li>
        <li><strong>Motors:</strong> All arm joints are powered by servo motors, which are controlled using the Adafruit ServoKit library for precise movements.</li>
        <li><strong>Voice Interaction:</strong> I added a microphone and speaker for voice control and feedback. Saying "activate now" triggers the arm, which responds with phrases like “Arm activated” before starting its routine.</li>
        <li><strong>Control Software:</strong> The project is driven by a set of Python files that work together like this:
          <ul>
            <li><a href="https://github.com/nischalkharel/RoboticArm/blob/main/arm.py" class="highlight-link">
              <span class="highlight"><strong>arm.py:</strong></span></a> This is the main file that ties everything together. It listens for voice commands and coordinates the overall process, from detecting the block to moving the arm.</li>
            <li><a href="https://github.com/nischalkharel/RoboticArm/blob/main/camera.py" class="highlight-link">
              <span class="highlight"><strong>camera.py:</strong></span></a> This handles detecting the ArUco marker, calculating the block's position in x, y, z, and returning those coordinates.</li>
            <li><a href="https://github.com/nischalkharel/RoboticArm/blob/main/calculate_angles_for.py" class="highlight-link">
              <span class="highlight"><strong>calculate_angles_for.py:</strong></span></a> Using the block’s coordinates, this file calculates the angles for each joint of the arm. I simplified inverse kinematics into something more intuitive for me, which worked better than traditional IK.</li>
            <li><a href="https://github.com/nischalkharel/RoboticArm/blob/main/move_motor.py" class="highlight-link">
              <span class="highlight"><strong>move_motor.py:</strong></span></a> This file sends the calculated angles to the servos, making the arm move smoothly.</li>
            <li><a href="https://github.com/nischalkharel/RoboticArm/blob/main/audio_in.py" class="highlight-link">
              <span class="highlight"><strong>audio_in.py</strong></span></a> and <a href="https://github.com/nischalkharel/RoboticArm/blob/main/audio_out.py" class="highlight-link">
                <span class="highlight"><strong>audio_out.py:</strong></span></a> These files handle the voice interaction. One listens for commands through the microphone, and the other sends audio feedback through the speaker.</li>
          </ul>
        </li>
      </ul>

      <div class="image-gallery">
        <img src="arm_transparent.png" alt="Robotic Arm Design" style="width: 300px; height: auto;">
        <div class="caption-box">
            <p>The image above is of the final design. I have the speaker and camera right in the front plate of my small enclosure. The mic is on the right side of the arm sticking out. Also, you can see how the (pink) servos were used. Also in the back you can see the block with ArUco that I used, but I will have more pictures of it later in the blog.</p>
        </div>
      </div>
      <h2 class="subtitle">Expanding on Previous Work</h2>
      <p>This project builds on a mix of existing tools and my own modifications:</p>
      <ul>
        <li><strong>Servo Control:</strong> I initially tried manually programming servo movements, but they were too jerky. The Adafruit ServoKit library made a huge difference, letting me smoothly move the joints to exact angles.</li>
        <li><strong>Custom IK Logic:</strong> I spent days trying to understand traditional inverse kinematics. While I got it partially working, it wasn’t accurate enough for my setup. So, I developed a simpler version of IK that skips matrices and uses trigonometry that made more sense to me. (I’ll explain the math later in this blog.)</li>
        <li><strong>ArUco Markers:</strong> Using the ArUco library, I detected and calculated distances to the block. However, the library’s output wasn’t perfect, so I tweaked the distance values manually to improve accuracy.</li>
        <li><strong>Stereo Camera:</strong> Although I didn’t use the stereo camera in the final setup, it was a great learning experience. I calibrated it using OpenCV’s checkerboard calibration and got it working, but it wasn’t more accurate than the Arducam setup. You can find my stereo camera code and experiments on my GitHub repository if you’re curious.</li>
      </ul>

      <section id="ik-glimpse">
        <div class="image-container">
            <img src="ipad_math.jpg" alt="Handwritten IK Math Notes" class="image">
            <img src="ipad_math_arm.jpg" alt="IK Applied to Arm Diagram" class="image">
        </div>
        <div class="caption-box">
            <p>These are some glimpses of how I expanded on what I learned about inverse kinematics (IK) to make it simpler for my robotic arm. I will explain these more in later sections.</p>
        </div>
    </section>
    

    
      <h2 class="subtitle">Purpose</h2>
      <p>This project was a way for me to dive deeper into robotics, math, and computer vision. It’s not just a robotic arm—it’s a system where hardware and software work together in sync. The voice control and feedback added personality to the arm, making it more interactive and fun to use. I’m really proud of what I built, and there’s so much potential to expand it further, like sorting objects or even playing chess.</p>
    </section>
  



    <section id="preliminary-design-verification">
      <h1>Preliminary Design Verification</h1>
  
      <h2 class="subtitle">Assembly and Servo Integration</h2>
      <p>The robotic arm was assembled using pre-built components and servos. These servos were connected to a Raspberry Pi through a old servo controller that I had (I will try to find the exact type on amazon and put the link at the end of the blog) and controlled using the Adafruit ServoKit library. Each servo was responsible for specific movements: the base for horizontal rotation, the shoulder and elbow for vertical positioning, the wrist for up-and-down movement, and the gripper for opening and closing. This setup provided precise control over the arm’s movements.</p>
  
      <h2 class="subtitle">Motor Testing and Manual Calibration</h2>
      <p>Before moving to advanced features like computer vision and inverse kinematics, I wrote a program (<a href="https://github.com/nischalkharel/RoboticArm/blob/main/KeyboardControlledArm.py" class="highlight-link">
    <span class="highlight"><strong>KeyboardControlledArm.py</strong></span></a>) to manually control the arm's motors. The program mapped keyboard keys to specific joints for precise movement testing. For example:</p>
      <ul>
          <li><strong>w/s:</strong> Control the shoulder's up-and-down motion.</li>
          <li><strong>a/d:</strong> Control the wrist's up-and-down movement.</li>
          <li><strong>Arrow Keys:</strong> Control the base rotation (left/right) and the elbow's up-and-down motion.</li>
          <li><strong>o/c:</strong> Open and close the gripper.</li>
      </ul>
      <p>The program also displayed real-time angles of all servos on the command line, helping me understand how angle adjustments corresponded to the arm's physical movements.</p>
  
      <p>Here is an example of how the program mapped keyboard inputs to control the servos:</p>
      <div class="code-block">
          <pre><code>
  <a href="https://github.com/nischalkharel/RoboticArm/blob/main/KeyboardControlledArm.py" class="highlight-link">
    <span class="highlight"><strong>KeyboardControlledArm.py</strong></span></a>
  # Shoulder control
  if key == ord('w'):
      if shoulder_angle < SHOULDER_MAX:
          shoulder_angle += ANGLE_STEP
  elif key == ord('s'):
      shoulder_angle -= ANGLE_STEP
  
  # Wrist control
  if key == ord('a'):
      if wrist_angle > WRIST_MIN:
          wrist_angle -= ANGLE_STEP
  elif key == ord('d'):
      if wrist_angle < WRIST_MAX:
          wrist_angle += ANGLE_STEP
          </code></pre>
      </div>
  
      <h2 class="subtitle">Key Features of the Testing Program</h2>
      <p>The testing program had several key features:</p>
      <ul>
          <li>Real-time angle display on the command line.</li>
          <li>Dynamic angle limit adjustments to prevent collisions.</li>
          <li>Smooth movements achieved through small angle increments.</li>
          <li>Intuitive keyboard controls for easy testing and calibration.</li>
      </ul>
  
      <h2 class="subtitle">Testing Outcomes</h2>
      <p>This program helped me:</p>
      <ul>
          <li>Understand how changes in angles correspond to physical movements.</li>
          <li>Identify safe operating ranges for each servo.</li>
          <li>Ensure smooth, realistic motion by fine-tuning angle adjustments.</li>
      </ul>
  
      <p>Below is an example of how the program updated the servo angles in real time:</p>
      <div class="code-block">
          <pre><code>
  <a href="https://github.com/nischalkharel/RoboticArm/blob/main/KeyboardControlledArm.py" class="highlight-link">
    <span class="highlight"><strong>KeyboardControlledArm.py</strong></span></a>
  # Update the servos with the new angles
  kit.servo[0].angle = base_angle
  kit.servo[1].angle = shoulder_angle
  kit.servo[2].angle = elbow_angle
  kit.servo[3].angle = wrist_angle
  kit.servo[4].angle = gripper_angle
          </code></pre>
      </div>
  
      <h2 class="subtitle">Getting Things to Work in Real Life</h2>
      <p>This testing phase gave me a better understanding of how the arm moves and reacts. Manually controlling the motors helped me identify calibration issues, like how small errors in servo movements could affect the gripper’s ability to pick up objects. These early tests built a strong foundation for moving to computer vision and automated joint angle calculations.</p>
  </section>
  



  <section id="design-implementation">
    <h1>Design Implementation</h1>

    <h2 class="subtitle">Overall System Overview</h2>
    <p>The robotic arm system integrates three main areas: computer vision for block detection, motor control for precise arm movements, and voice interaction for user commands. The camera, mounted on the arm's base, captures the workspace and detects ArUco markers to determine the block's position. These coordinates (x, y, z) are used to calculate joint angles, which the servos then execute to pick up the block and place it in a predefined location. The voice command feature allows the system to feel more interactive, enabling activation with a simple phrase, “activate now,” followed by verbal feedback from the arm.</p>

    <h2 class="subtitle">Subcomponents Developed/Used</h2>
    <ul>
        <li><strong>Hardware:</strong>
            <ul>
                <li><strong>Robotic Arm Shell:</strong> A pre-built arm structure, modified with servo motors for the joints and gripper.</li>
                <li><strong>Servo Motors:</strong> Five motors responsible for the base rotation, shoulder, elbow, wrist, and gripper movement.</li>
                <li><strong>Camera:</strong> An Arducam mounted on the arm's base, configured to detect ArUco markers for block localization.</li>
                <li><strong>Audio Input and Output:</strong>
                    <ul>
                        <li><strong>Microphone:</strong> Captures user commands for interaction.</li>
                        <li><strong>Speaker:</strong> Provides voice feedback to users.</li>
                    </ul>
                </li>
            </ul>
        </li>
        <li><strong>Software:</strong>
            <ul>
                <li><strong>Camera System:</strong> OpenCV’s ArUco library for marker detection and distance measurement. The <code>camera.py</code> module handles real-time image processing and calculates block coordinates.</li>
                <li><strong>Motor Control:</strong> The <code>calculate_angles_for.py</code> module computes joint angles using a simplified inverse kinematics approach. The <code>move_motor.py</code> module handles smooth servo movements, ensuring precise arm positioning.</li>
                <li><strong>Voice Interaction:</strong> Speech recognition via <code>speech_recognition</code> library to detect user commands, and <code>espeak</code> for generating responses from the arm.</li>
                <li><strong>Main Controller:</strong> The <code>arm.py</code> file integrates all subsystems, acting as the central logic hub.</li>
            </ul>
        </li>
    </ul>

    <h2 class="subtitle">Design Process and Challenges</h2>
    <p>This project was my first real experience using a Raspberry Pi on my own (I had used it in a class before, but it was a structured lab with step-by-step instructions, so I didn’t get much room to experiment). Diving into this project was a whole new level of trial and error, especially because I was trying to figure out everything from scratch.</p>
    <ol>
        <li><strong>Camera System Development:</strong>
            <p>At first, I thought using a stereo camera would be the easiest way to measure depth and detect the block. Boy, was I wrong! The stereo camera I ordered didn’t have much documentation, so I spent hours—no, days—trying to get it to work. I installed so many libraries, tried countless configurations, and just when I thought it would never work, I finally managed to get it running. But even then, I wasn’t out of the woods.</p>
            <p>My original idea was to use the camera to recognize the block's color (blue in my case) and estimate its distance by comparing its size in the image to its actual size. That worked... kind of. Until the lighting changed. Then everything fell apart. It was so inconsistent that I couldn’t trust it at all.</p>
            <p>After some research, I stumbled upon ArUco markers, and let me tell you, they were a game changer. They made everything way more consistent by providing clear features for the camera to detect, even with changing lighting. Using OpenCV’s ArUco library, I was able to calculate the block’s position based on the marker’s size and orientation:</p>
            <div class="code-block">
                <pre><code>
# Detect ArUco markers and estimate pose
corners, ids, _ = aruco.detectMarkers(gray, aruco_dict, parameters=parameters)
if ids is not None:
    rvecs, tvecs, _ = aruco.estimatePoseSingleMarkers(corners, 0.0235, camera_matrix, dist_coeffs)
    for i in range(len(ids)):
        x_m, y_m, z_m = tvecs[i][0]  # Extract (x, y, z) in meters
        x_in, y_in, z_in = x_m * 39.3701, y_m * 39.3701, z_m * 39.3701  # Convert to inches
        return x_in, y_in, z_in
                </code></pre>
            </div>
        </li>
        <li><strong>Switching to a Single Camera:</strong>
            <p>Once I got the markers working with the stereo camera, I had the thought, “Do I even need the stereo camera?” Turns out, I didn’t. A single camera with ArUco markers worked just as well for my setup. It simplified everything—no more messing with two camera feeds, less processing power needed, and fewer headaches overall.</p>
        </li>
        <li><strong>Motor Control and Inverse Kinematics:</strong>
            <p>Once I had the block’s position figured out, the next challenge was moving the arm to pick it up. Instead of using traditional matrix-based inverse kinematics (IK), which felt way too complicated for me, I came up with a simpler method using trigonometry. This approach let me calculate the joint angles without diving into the deep end of IK theory.</p>
            <div class="code-block">
                <pre><code>
# Smoothly move a motor to the specified angle
def move_motor(motor_id, target_angle):
    step = 1 if target_angle > current_angle else -1
    for angle in range(current_angle, target_angle, step):
        kit.servo[motor_id].angle = angle
        sleep(0.02)
    kit.servo[motor_id].angle = target_angle
                </code></pre>
            </div>
        </li>
        <li><strong>Voice Interaction:</strong>
            <p>One of the coolest parts of the project was adding voice commands. I used <code>speech_recognition</code> to listen for commands like “activate now” and <code>espeak</code> to make the arm respond with phrases like “Arm activating!” This feature made the system feel more alive and interactive, which I really enjoyed.</p>
        </li>
    </ol>
</section>



<section id="ik-calculation">
  <h1 class="subtitle">Simplified Inverse Kinematics (IK)</h1>

  <p>In this section, I’ll explain the simplified approach I used for calculating the joint angles of the robotic arm. My goal was to determine the angles for the base, shoulder, elbow, and wrist motors to make the gripper reach a block located on the ground at a fixed height <span class="math-inline">(y = 0.5 inches)</span>. Here’s the step-by-step process:</p>

  <h2 class="subtitle_2">The Thought Process</h2>
  <p>To simplify things, I assumed the gripper fingers would initially be <strong>vertical</strong> (pointing straight down to the ground). From there:</p>
  <ul>
      <li><strong>Start with the wrist:</strong> I adjust the vertical <span class="math-inline">G<sub>y</sub></span> and horizontal <span class="math-inline">G<sub>z</sub></span> positions of the wrist joint.</li>
      <li><strong>Check reachability:</strong> I calculate the total distance <span class="math-inline">R</span> from the shoulder joint to the wrist using the Pythagorean theorem. If this distance exceeds the total length of the arm sections <span class="math-inline">(L2 + L3)</span>, I increment <span class="math-inline">G<sub>z</sub></span> to tilt the gripper.</li>
      <li><strong>Find joint angles:</strong> Using trigonometry, I calculate the angles for the elbow, shoulder, and wrist motors.</li>
  </ul>

  <h2 class="subtitle_2">Step-by-Step Explanation</h2>
  <ul>
      <li><strong>Step 1:</strong> Calculate the base angle <span class="math-inline">θ<sub>base</sub></span> using the block's <span class="math-inline">(x, z)</span> coordinates:</li>
      <div class="math-block">
          <p>θ<sub>base</sub> = atan2(X, Z)</p>
          <p>θ<sub>base</sub> = 90° - θ<sub>base</sub> (adjusted for motor offset)</p>
      </div>

      <li><strong>Step 2:</strong> Set the initial wrist position:</li>
      <div class="math-block">
          <p>G<sub>z</sub> = 0</p>
          <p>G<sub>y</sub> = 6.5 inches (gripper length)</p>
      </div>

      <li><strong>Step 3:</strong> Calculate the height <span class="math-inline">H</span> and horizontal distance <span class="math-inline">D</span> from the shoulder to the wrist:</li>
      <div class="math-block">
          <p>H = L<sub>1</sub> + G<sub>y</sub> - Y</p>
          <p>D = √(X² + Z²) - G<sub>z</sub></p>
      </div>

      <li><strong>Step 4:</strong> Use the Pythagorean theorem to calculate the total distance <span class="math-inline">R</span> from the shoulder to the wrist:</li>
      <div class="math-block">
          <p>R = √(H² + D²)</p>
      </div>

      <li><strong>Step 5:</strong> Check if <span class="math-inline">R</span> is reachable. If <span class="math-inline">R > (L<sub>2</sub> + L<sub>3</sub>)</span>, increment <span class="math-inline">G<sub>z</sub></span> to tilt the wrist and reduce <span class="math-inline">G<sub>y</sub></span>.</li>
  </ul>

  <h2 class="subtitle_2">Example Walkthrough</h2>
  <div class="example-walkthrough">
      <p>Let’s say the block is located at <span class="math-inline">(x, y, z) = (3, 0.5, 7)</span>. Here’s how the calculations would proceed:</p>
      <ul>
          <li><strong>Base angle:</strong>
              <span class="math-inline">θ<sub>base</sub> = atan2(3, 7) = 23.2°</span></li>
          <li>Adjust for motor offset:
              <span class="math-inline">θ<sub>base</sub> = 90 - 23.2 = 66.8°</span></li>
          <li><strong>Initial wrist position:</strong>
              <span class="math-inline">G<sub>z</sub> = 0</span>,
              <span class="math-inline">G<sub>y</sub> = 6.5</span></li>
          <li><strong>Height and horizontal distance:</strong>
              <div class="math-block">
                  <p>H = 10.0</p>
                  <p>D = 7.62</p>
              </div>
          </li>
          <li><strong>Shoulder-to-wrist distance:</strong>
              <div class="math-block">
                  <p>R = √(10.0² + 7.62²) = 12.62</p>
              </div>
              <p>Since <span class="math-inline">R > 9.45</span>, increment <span class="math-inline">G<sub>z</sub></span>.</p>
          </li>
          <li><strong>Iterate until:</strong>
              <span class="math-inline">R ≤ 9.45</span>. Update <span class="math-inline">G<sub>z</sub></span> and <span class="math-inline">G<sub>y</sub></span> at each step.</li>
          <li>Calculate elbow, shoulder, and wrist angles:</li>
      </ul>
      <div class="code-block">
          <code>
# Example Python Code for Angle Calculation
cos_theta_elbow = (L2**2 + L3**2 - R**2) / (2 * L2 * L3)
theta_elbow = math.acos(cos_theta_elbow)
theta_elbow_deg = math.degrees(theta_elbow)

cos_theta_shoulder = (L2**2 + R**2 - L3**2) / (2 * L2 * R)
theta_shoulder = math.acos(cos_theta_shoulder)
theta_shoulder_deg = math.degrees(theta_shoulder)
          </code>
      </div>
  </div>

  <p>At the end of this process, if valid angles are found for the shoulder and elbow joints, the arm will move to grab the block. If not, the block is considered unreachable due to the physical limitations of the arm.</p>
</section>







  
</main>


  <script>
    function goBack() {
      window.history.back();
    }

    function toggleMenu() {
      const menu = document.getElementById('popup-menu');
      menu.style.display = menu.style.display === 'block' ? 'none' : 'block';
    }
  </script>
</body>
</html>

